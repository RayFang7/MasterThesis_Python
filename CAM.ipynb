{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from gradcam.utils import visualize_cam\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "import nets\n",
    "from lib import get_datatransformer\n",
    "from arg import get_params\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nets.vggnet(\"\")\n",
    "model.load_state_dict(torch.load(\"temp.dict\"))\n",
    "args = vars(get_params())\n",
    "transformer = get_datatransformer(args,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987e7f043c0f4144a8ff74fa069d5ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "fig = plt.figure(0)\n",
    "ax1 = fig.add_subplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17658_ASMI_ISCIN_p6065_ap7.jpg\n",
      "tensor([False], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '17658_ASMI_ISCIN_p6065_ap7.jpg False')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 0;\n",
    "roa = {0:\"0_MI\",1:\"1_H\"}\n",
    "dataset_path = '/home/ray/TrainingData/419/ap/10/'\n",
    "dataset_path += roa[label]+\"/\"\n",
    "file_list = os.listdir(dataset_path)\n",
    "img_name= file_list[round(random.uniform(0,len(file_list)))]\n",
    "pil_img = PIL.Image.open(dataset_path+img_name)\n",
    "torch_img = transformer['val'](pil_img).to(device)\n",
    "normed_torch_img = torch_img.unsqueeze(0).to(device)\n",
    "print(img_name)\n",
    "_,pred = torch.max(model(normed_torch_img),1)\n",
    "print(pred == label)\n",
    "plt.title(img_name+\" \"+str(pred.item()==label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6113, -0.6797]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(normed_torch_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    dict(model_type='vgg', arch=model, layer_name='features_51'),\n",
    "]\n",
    "for config in configs:\n",
    "    config['arch'].to(device).eval()\n",
    "\n",
    "cams = [\n",
    "    [cls.from_config(**config) for cls in (GradCAM, GradCAMpp)]\n",
    "    for config in configs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = []\n",
    "images2 = []\n",
    "for gradcam, gradcam_pp in cams:\n",
    "    mask, _ = gradcam(normed_torch_img)\n",
    "    heatmap, result = visualize_cam(mask, torch_img)\n",
    "\n",
    "    mask_pp, _ = gradcam_pp(normed_torch_img)\n",
    "    heatmap_pp, result_pp = visualize_cam(mask_pp, torch_img)\n",
    "    \n",
    "    images.extend([torch_img.cpu(), heatmap, heatmap_pp, result, result_pp])\n",
    "    images2.extend([torch_img.cpu(), heatmap_pp,result_pp])\n",
    "    \n",
    "grid_image = make_grid(images2, nrow=len(images2))\n",
    "pil_image = transforms.ToPILImage()(grid_image)\n",
    "plt.imshow(pil_image)\n",
    "plt.axis('off')\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5828, -0.6457]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
